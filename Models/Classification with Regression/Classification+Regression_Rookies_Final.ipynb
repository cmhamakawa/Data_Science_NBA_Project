{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing, sklearn.decomposition, sklearn.linear_model, sklearn.pipeline, sklearn.metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn_pandas import DataFrameMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df = pd.read_csv('https://raw.githubusercontent.com/cmhamakawa/Data_Science_NBA_Project/master/Datasets/v2preprocessed_nba_dataset(1990-2020).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = [str(list(adv_df['SalStartYr'])[i]) + \"-\" + str(list(adv_df['SalEndYr'])[i]) for i in range(len(list(adv_df['SalEndYr'])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(adv_df['Player'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adv_df.drop(adv_df.columns[0], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#670000\n",
    "# christine_subset = adv_df[['FG', 'FTA', 'AST', 'TRB', 'PTS', 'BLK', 'years_of_exp','Salary','SalStartYr','TOV','Age','G','Pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 690000\n",
    "# christine_subset = adv_df[['FG', 'FT', 'AST', 'DRB', 'PTS', 'BLK', 'years_of_exp','Salary','SalStartYr','TOV','Age','G','Pos','PF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christine_subset = adv_df[['FG', 'FTA', 'AST', 'TRB', 'PTS', 'BLK', 'years_of_exp','Salary','SalStartYr','TOV','Age','G','Pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# christine_subset.set_index('Player',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christine_subset = christine_subset[christine_subset['years_of_exp'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christine_subset.drop(columns = 'years_of_exp', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christine_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset = adv_df[adv_df['years_of_exp'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot all variables (excluding the target variable) against the target variable (sales)\n",
    "# for i in list(subset.drop(columns = ['Player','StartYr','EndYr','SalEndYr','Salary','SalaryInfl','salary_cap_adjusted','salary_cap','Per_of_Salary_Cap']).columns):\n",
    "#     sns.catplot(x = i, y = 'Salary', data = subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first quartile\n",
    "q1 = christine_subset['Salary'].quantile(.25)\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first quartile\n",
    "q3 = christine_subset['Salary'].quantile(.75)\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interquartile range\n",
    "iqr = q3 - q1\n",
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower limit for outliers, lower than 0 so no need to account for\n",
    "lower = q1 - 1.5 * iqr\n",
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upper limit for outliers\n",
    "upper = q3 + 1.5 * iqr\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# christine_subset = christine_subset[(christine_subset['Salary'] > christine_subset['Salary'].quantile(low)) & (christine_subset['Salary'] < christine_subset['Salary'].quantile(high))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christine_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = christine_subset[christine_subset['Salary'] >= upper]\n",
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christine_subset = christine_subset[christine_subset['Salary'] < upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = christine_subset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2['SalStartYr'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "christine_subset['SalStartYr'] = le.fit_transform(christine_subset['SalStartYr'])\n",
    "christine_subset['Pos'] = le.fit_transform(christine_subset['Pos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# christine_subset['Pos'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {list(set(test2['SalStartYr']))[i]: list(set(christine_subset['SalStartYr']))[i] for i in range(len(list(set(test2['SalStartYr']))))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others = christine_subset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# for column, alias in zip(others, others):\n",
    "#     stuff = ([column], sklearn.preprocessing.MinMaxScaler(), {'alias': alias})\n",
    "#     features.append(stuff)\n",
    "\n",
    "# mapper = DataFrameMapper(features,df_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_elbow = mapper.fit_transform(christine_subset.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elbow = christine_subset.drop(columns = 'Salary', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_elbow = christine_subset[['Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distortions = []\n",
    "inertias = []\n",
    "\n",
    "K = range(1, 10)\n",
    "\n",
    "for k in K:\n",
    "    # Building and fitting the model\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(to_elbow)\n",
    "    kmeanModel.fit(to_elbow)\n",
    "\n",
    "    distortions.append(sum(np.min(cdist(to_elbow, kmeanModel.cluster_centers_,\n",
    "                                        'euclidean'), axis=1)) / to_elbow.shape[0])\n",
    "\n",
    "    inertias.append(kmeanModel.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('The Elbow Method using Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(to_elbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elbow['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elbow['Cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christine_subset['Cluster'] = to_elbow['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# christine_subset['SalStartYr'] = le.fit_transform(christine_subset['SalStartYr'])\n",
    "# christine_subset['Tm'] = le.fit_transform(christine_subset['Tm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# christine_subset = christine_subset.join(fixed_df.iloc[:,0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christine_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Well Can I Predict Clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# christine_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others = christine_subset.drop(columns = ['Cluster','Salary'], axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [('Cluster', None), ('Salary', None)]\n",
    "# for column, alias in zip(others, others):\n",
    "#     stuff = ([column], sklearn.preprocessing.MinMaxScaler(), {'alias': alias})\n",
    "#     features.append(stuff)\n",
    "\n",
    "# mapper = DataFrameMapper(features,df_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# christine_subset = mapper.fit_transform(christine_subset.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = christine_subset.drop(columns = ['Cluster','Salary'], axis = 1)\n",
    "y = christine_subset[['Cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_lists():\n",
    "#     \"\"\"\n",
    "#     Create an \"active\" list with a single random column\n",
    "#     from X.columns and an \"inactive\" list with \n",
    "#     all remaining columns. \n",
    "#     \"\"\"\n",
    "#     # grab a single random column\n",
    "#     # list not a single elemet therefore  square brackets\n",
    "#     active = [np.random.choice(df.columns)]\n",
    "    \n",
    "#     # make a list of all the other columns\n",
    "#     inactive = list(df.columns)\n",
    "#     inactive.remove(active[0])\n",
    "#     return active, inactive\n",
    "    \n",
    "# def move(col, active, inactive, mode = \"activate\"):\n",
    "#     \"\"\"\n",
    "#     Activate or deactivate a single column\n",
    "#     by moving it between the active and inactive\n",
    "#     lists. \n",
    "#     Does not modify active or inactive -- instead \n",
    "#     returns copies. \n",
    "#     \"\"\"\n",
    "#     # create copies (still lists!)\n",
    "#     new_active = active.copy()\n",
    "#     new_inactive = inactive.copy()\n",
    "    \n",
    "#     if mode == \"activate\":\n",
    "#         # if we are activating a column\n",
    "#         new_inactive.remove(col)\n",
    "#         # add col to the active list\n",
    "#         new_active.append(col)\n",
    "    \n",
    "#     # if we are deactivating a column\n",
    "    \n",
    "#     if mode == \"deactivate\":\n",
    "#         new_active.remove(col)\n",
    "#         new_inactive.append(col)\n",
    "    \n",
    "#     # return copies\n",
    "#     return new_active, new_inactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def greedy_stagewise_feature_selection(model, X, y, n_iters = 60):\n",
    "    \n",
    "#     # initialize with a single, randomly selected column\n",
    "#     active, inactive = initialize_lists()\n",
    "    \n",
    "#     # initialize the best CV score\n",
    "#     best_CV = 0\n",
    "    \n",
    "#     # main loop, n_iters times (20 times by default, adding subtracting columns from active list)\n",
    "#     for i in range(n_iters):\n",
    "#         # alternate between activating and deactivating\n",
    "#         for mode in [\"activate\", \"deactivate\"]:\n",
    "        \n",
    "#             # if mode is \"activate\" and there are any remaining inactive\n",
    "#             # columns, randomly select one. Otherwise, continue\n",
    "#             if (mode == \"activate\") and (len(inactive) > 0):\n",
    "#                 col = np.random.choice(inactive)\n",
    "    \n",
    "            \n",
    "#             # if mode is \"deactivate\" and if there at least 2 active\n",
    "#             # columns then pick a random active column\n",
    "#             # always need atleast one column in inactive\n",
    "#             if (mode == \"deactivate\") and (len(active) >= 2):\n",
    "#                 col = np.random.choice(active)\n",
    "            \n",
    "#             # create a new, proposed active list by moving\n",
    "#             # col between lists\n",
    "            \n",
    "#             new_active, new_inactive = move(col, active, inactive, mode)\n",
    "            \n",
    "#             # compute the CV score\n",
    "#             # 7 splits (arbitrary number)\n",
    "#             CV_score = cross_val_score(LR, X[new_active], y, cv = 7).mean()\n",
    "            \n",
    "#             # if the CV score is an improvement, update the \n",
    "#             # active and inactive column sets. \n",
    "            \n",
    "#             if (CV_score > best_CV) and (len(new_active) >=1):\n",
    "#                 # \"steeping into the ocean\" rather than running towards the sand\n",
    "#                 best_CV = CV_score\n",
    "#                 active = new_active\n",
    "#                 inactive = new_inactive\n",
    "            \n",
    "#             # see if cv score is improved based on how many columns we add\n",
    "#             print(\"Number of columns: \" + str(len(active)) + \". CV score: \" + str(best_CV))\n",
    "            \n",
    "#     # returns the list of column names with BEST CV score!\n",
    "#     return active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "cross_val_score(LR, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vals = np.linspace(0, 3, 10)\n",
    "c_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "best_score = 0\n",
    "best_c = 0\n",
    "\n",
    "# c_vals from 0-10\n",
    "c_vals = np.linspace(0, 3, 20)\n",
    "\n",
    "# loop through possible c_vals\n",
    "for c_val in c_vals:\n",
    "    \n",
    "    # evaluate the model with the current c_val\n",
    "    LR = LogisticRegression(C = c_val)\n",
    "    cv_score = cross_val_score(LR, X_train, y_train, cv=5).mean()\n",
    "    ax.scatter(c_val, cv_score, color = \"black\")\n",
    "    \n",
    "    # check if we've beaten our previous score\n",
    "    if cv_score > best_score:\n",
    "        best_c = c_val\n",
    "        best_score = cv_score\n",
    "\n",
    "l = ax.set(title = \"Best C : \" + str(best_c),\n",
    "       xlabel = \"C\", \n",
    "       ylabel = \"CV Score\")\n",
    "ax.scatter(best_c, best_score, color = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C = best_c)\n",
    "LR.fit(X_train, y_train)\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = DecisionTreeClassifier(max_depth = 2)\n",
    "cross_val_score(T, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "# cross validation for each of the possible model depths 1-30\n",
    "for d in range(1,30):\n",
    "    T = DecisionTreeClassifier(max_depth = d)\n",
    "    # Average cv_score acheived in cross validation\n",
    "    cv_score = cross_val_score(T, X_train, y_train, cv=10).mean()\n",
    "    # plot avg cv_score (in black)\n",
    "    ax.scatter(d, cv_score, color = \"black\")\n",
    "    # identify the best possible depth by cv_score\n",
    "    if cv_score > best_score:\n",
    "        best_depth = d\n",
    "        best_score = cv_score\n",
    "\n",
    "#highlight the best depth, best score value in red\n",
    "ax.scatter(best_depth, best_score, color = \"red\")\n",
    "\n",
    "# show best depth in title \n",
    "# plot tells us the depth that acheived the best score under cross validation \n",
    "# we now have a good estimate about the optimal depth/complexity of model\n",
    "l = ax.set(title = \"Best Depth : \" + str(best_depth),\n",
    "       xlabel = \"Depth\", \n",
    "       ylabel = \"CV Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = DecisionTreeClassifier(max_depth = best_depth)\n",
    "T.fit(X_train, y_train)\n",
    "T.score(X_train, y_train), T.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = MLPClassifier(verbose = True, max_iter = 1000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# decision_tree_model_pkl = open('rookie_dt.pkl', 'wb')\n",
    "# pickle.dump(T, decision_tree_model_pkl)\n",
    "# decision_tree_model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_0 = christine_subset[christine_subset['Cluster'] == 0]\n",
    "# salary_0 = cluster_0['Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others = christine_subset.drop(columns = 'Salary', axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [('Salary', None)]\n",
    "# for column, alias in zip(others, others):\n",
    "#     stuff = ([column], sklearn.preprocessing.MinMaxScaler(), {'alias': alias})\n",
    "#     features.append(stuff)\n",
    "\n",
    "# mapper = DataFrameMapper(features,df_out = True)\n",
    "\n",
    "# christine_subset = mapper.fit_transform(christine_subset.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# christine_subset = christine_subset[christine_subset['Cluster'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training and test sets, encode\n",
    "X = christine_subset.drop(columns = ['Salary'], axis=1)\n",
    "y = christine_subset[['Salary']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_X = X[X['SalStartYr'] == 29]\n",
    "# non_latest_X = X[X['SalStartYr'] != 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_y = y[y.index.isin(latest_X.index)]\n",
    "# non_latest_y = y[y.index.isin(non_latest_X.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #splitting training and testing sets, 70/30\n",
    "# X_train, X_test, y_train, y_test = non_latest_X, latest_X, non_latest_y, latest_y\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #splitting training and testing sets, 70/30\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,  stratify = X['Cluster'])\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting training and testing sets, 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base parameters\n",
    "#optimize both bias and variance\n",
    "params = {\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'reg:squarederror',\n",
    "}\n",
    "\n",
    "params['eval_metric'] = 'rmse'\n",
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial run\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabular data\n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'rmse'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune max_depth and min_child_weight\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(1, 20)\n",
    "    for min_child_weight in range(1, 20)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through combinations of parameter values and get lowest value\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    \n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameter values to most optimal values\n",
    "params['max_depth'] = best_params[0]\n",
    "params['min_child_weight'] =  best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune subsample and colsample\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(1, 11)]\n",
    "    for colsample in [i/10. for i in range(1, 11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through combinations of parameter values and get lowest value\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    \n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameter values to optimal values\n",
    "params['subsample'] = best_params[0]\n",
    "params['colsample_bytree'] = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through combinations of parameter values and get lowest value\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    \n",
    "    params['eta'] = eta\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics=['rmse'],\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\\n\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, RMSE: {}\".format(best_params, min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameter value to optimal value\n",
    "params['eta'] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "print(\"Best RMSE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model to optimal iteration\n",
    "num_boost_round = model.best_iteration + 1\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE score\n",
    "mean_squared_error(best_model.predict(dtest), y_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save model\n",
    "# best_model.save_model(\"cluster0_rookie.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model and predict\n",
    "# loaded_model = xgb.Booster()\n",
    "# loaded_model.load_model(\"cluster0_rookie.model\")\n",
    "# predictions = [round(i) for i in loaded_model.predict(xgb.DMatrix(X_test))]\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #RMSE score\n",
    "# mean_squared_error(predictions, y_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall: 968145.6208176024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 0: 989329.9164214467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 1: 920915.4618404186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 2: 868250.7251829752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame(np.column_stack([predictions, y_test]), columns = ['predictions','y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['index'] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=data['index'], y=data['predictions'],\n",
    "#                     mode='lines',\n",
    "#                     name='predicted'))\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=data['index'], y=data['y_test'],\n",
    "#                     mode='lines',\n",
    "#                     name='observed'))\n",
    "\n",
    "# fig.update_layout(title = 'Rookie Numbers (100 Players)')\n",
    "# fig.update_xaxes(title = 'Player')\n",
    "# fig.update_yaxes(title = 'Salary ($)')\n",
    "# fig.write_json(\"rookie_RMSE.json\") \n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Individual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# christine_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # corresponds to the 2020 season\n",
    "# test = christine_subset[(christine_subset['SalStartYr'] == 19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.drop(columns = ['Cluster','Salary'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.DataFrame([test.loc[5686]])\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['Cluster'] = T.predict(x)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_input = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.DataFrame(to_input.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = xgb.Booster()\n",
    "# loaded_model.load_model('cluster0_rookie.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.array([i for i in loaded_model.predict(xgb.DMatrix(final_df))])\n",
    "# predictions"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSU_NBA_Data_Cleaning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
